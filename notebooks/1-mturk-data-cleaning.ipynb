{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "# from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.stats.inter_rater\n",
    "\n",
    "import random\n",
    "random.seed(1)\n",
    "\n",
    "import copy\n",
    "import pickle\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.insert(1, '/ihome/xli/joh227/developer/ads/workspace/src/')\n",
    "\n",
    "from utils import (\n",
    "    load_json,\n",
    "    write_json,\n",
    "    load_jsonl,\n",
    "    write_jsonl\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dir = '/ihome/xli/joh227/developer/ads/workspace/'\n",
    "data_dir = curr_dir + 'data/'\n",
    "mturk_data_dir = curr_dir + 'data/mturk_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load MTurk Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 105)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mturk_raw_data = pd.read_csv(mturk_data_dir + 'subset_0.5/mturk_raw_results.0.5.1.csv')\n",
    "# mturk_raw_data.shape #, mturk_groundtruth.shape\n",
    "\n",
    "file_lst = [\n",
    "    mturk_data_dir + 'subset_0.5/mturk_raw_results.0.5.1.csv',\n",
    "    mturk_data_dir + 'subset_0.5/mturk_raw_results.0.5.csv',\n",
    "    mturk_data_dir + 'subset_1.2/mturk_raw_results.1.2.csv',\n",
    "    mturk_data_dir + 'subset_1.2/mturk_raw_results.1.2.1.csv',\n",
    "    mturk_data_dir + 'subset_1.1/mturk_raw_results.1.1.csv'\n",
    "    # mturk_data_dir + 'subset_1.1/Batch_5263776_batch_results.csv'\n",
    "]\n",
    "mturk_raw_data = []\n",
    "for file in file_lst:\n",
    "    tmp_df = pd.read_csv(file)\n",
    "    mturk_raw_data.append(tmp_df)\n",
    "mturk_raw_data = pd.concat(mturk_raw_data)\n",
    "mturk_raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 105)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_to_drop = []\n",
    "# ids_to_drop = [\"0/52390.jpg\", \"0/85300.jpg\"]\n",
    "mturk_raw_data = mturk_raw_data.loc[mturk_raw_data['Input.ads_id'].apply(lambda x: x not in ids_to_drop)].reset_index(drop=True)\n",
    "mturk_raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clearning and Score Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning unique_id\n",
    "mturk_raw_data['unique_id'] = range(mturk_raw_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Drop some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_drop = [\n",
    "    'HITTypeId',\n",
    "    'Title',\n",
    "    'Description',\n",
    "    'Keywords',\n",
    "    'Reward',\n",
    "    'CreationTime',\n",
    "    'MaxAssignments',\n",
    "    'RequesterAnnotation',\n",
    "    'AssignmentDurationInSeconds',\n",
    "    'AutoApprovalDelayInSeconds',\n",
    "    'Expiration',\n",
    "    'NumberOfSimilarHITs',\n",
    "    'LifetimeInSeconds',\n",
    "    # 'AssignmentId',\n",
    "    'AssignmentStatus',\n",
    "    'AcceptTime',\n",
    "    'SubmitTime',\n",
    "    'AutoApprovalTime',\n",
    "    'ApprovalTime',\n",
    "    'RejectionTime',\n",
    "    'RequesterFeedback',\n",
    "    'WorkTimeInSeconds',\n",
    "    'LifetimeApprovalRate',\n",
    "    'Last30DaysApprovalRate',\n",
    "    'Last7DaysApprovalRate',\n",
    "    'Input.example_1',\n",
    "    'Input.example_2',\n",
    "    'Input.image_url',\n",
    "    'Approve',\n",
    "    'Reject'\n",
    "]\n",
    "mturk_raw_data = mturk_raw_data.drop(columns=col_to_drop)\n",
    "mturk_raw_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Effective Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9688"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mturk_raw_data['effectiveness_correct'] = mturk_raw_data.apply(lambda x: x['Answer.effectiveness.' + x['Input.action_correct']], axis = 1)\n",
    "effectiveness_accuracy = sum(mturk_raw_data['effectiveness_correct']) / mturk_raw_data.shape[0]\n",
    "effectiveness_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2422"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(mturk_raw_data['effectiveness_correct']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mturk_raw_data['WorkerId'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Score Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 112)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_columns = ['pc', 'atypicality', 'artistic']\n",
    "answer_choices = {\n",
    "    'disagree': -1, \n",
    "    'neutral': 0, \n",
    "    'agree': 1\n",
    "}\n",
    "\n",
    "def helper_normalize_lst(lst, bin = 7): # normalize to bin = 7 (i.e. same as -3~3)\n",
    "    if max(lst) == min(lst): return [0] * len(lst)\n",
    "    \n",
    "    mean = np.mean(lst)\n",
    "    std = np.std(lst)\n",
    "    lst_norm = [(i - mean) / std for i in lst]\n",
    "    lst_norm_max = max(lst_norm)\n",
    "    lst_norm_min = min(lst_norm)\n",
    "    lst_norm = [\n",
    "        int((i - lst_norm_min) / (lst_norm_max - lst_norm_min) * bin - bin / 2)\n",
    "        for i in lst_norm\n",
    "    ]\n",
    "    return lst_norm\n",
    "    \n",
    "def find_acc_value(tmp_all_values, method, normalize_bin = 0):\n",
    "    if method == 'single_pos':\n",
    "        acc_values = [] \n",
    "        for i in range(len(tmp_all_values[0].values)):\n",
    "            item_value = 0\n",
    "            for lst in tmp_all_values:\n",
    "                lst = lst.values\n",
    "                if lst[i] == 1:\n",
    "                    item_value = 1\n",
    "            acc_values.append(item_value)\n",
    "        return acc_values\n",
    "    \n",
    "    tmp_sum_lst = []\n",
    "    for i in range(len(tmp_all_values[0].values)):\n",
    "        item_value = 0\n",
    "        tmp_sum = sum([lst.values[i] for lst in tmp_all_values])\n",
    "        tmp_sum_lst.append(tmp_sum)\n",
    "    \n",
    "    if normalize_bin:\n",
    "        tmp_sum_lst = helper_normalize_lst(tmp_sum_lst, normalize_bin)\n",
    "\n",
    "    acc_values = []\n",
    "    for tmp_sum in tmp_sum_lst:\n",
    "        if method == 'threshold_0' and tmp_sum > 0: item_value = 1\n",
    "        if method == 'threshold_3' and tmp_sum == 3: item_value = 1\n",
    "        if method == 'raw': item_value = tmp_sum\n",
    "        acc_values.append(item_value)\n",
    "    return acc_values\n",
    "\n",
    "normalize_bin = 3\n",
    "processed_data = []\n",
    "for worker_id in mturk_raw_data.WorkerId.unique():\n",
    "    tmp_df = copy.deepcopy(mturk_raw_data.query('WorkerId == \"{}\"'.format(worker_id)))\n",
    "    for col in tmp_columns:\n",
    "        # 1. value translation\n",
    "        tmp_all_values = []\n",
    "        for sub_question in ['_1', '_2', '_3']:\n",
    "            tmp_answer_values = []\n",
    "            for ans in answer_choices:\n",
    "                tmp_col = 'Answer.' + col + sub_question + '.' + ans\n",
    "                tmp_values = tmp_df[tmp_col].apply(lambda x: answer_choices[ans] if x else 0)\n",
    "                tmp_answer_values.append(tmp_values)\n",
    "            tmp_df['value_' + col + sub_question] = sum(tmp_answer_values)\n",
    "            tmp_all_values.append(sum(tmp_answer_values))\n",
    "        \n",
    "        # 2. value accumulation\n",
    "        tmp_df['acc_raw_' + col] = find_acc_value(tmp_all_values, method = 'raw')\n",
    "        tmp_df['acc_th0_' + col] = find_acc_value(tmp_all_values, method = 'threshold_0')\n",
    "        tmp_df['acc_th3_' + col] = find_acc_value(tmp_all_values, method = 'threshold_3')\n",
    "        tmp_df['acc_single_' + col] = find_acc_value(tmp_all_values, method = 'single_pos')\n",
    "\n",
    "        # 3. normalization \n",
    "\n",
    "        tmp_df['acc_norm_raw_' + col] = find_acc_value(tmp_all_values, method = 'raw', normalize_bin = normalize_bin)\n",
    "        tmp_df['acc_norm_th0_' + col] = find_acc_value(tmp_all_values, method = 'threshold_0', normalize_bin = normalize_bin)\n",
    "        tmp_df['acc_norm_th3_' + col] = find_acc_value(tmp_all_values, method = 'threshold_3', normalize_bin = normalize_bin)\n",
    "    processed_data.append(tmp_df)\n",
    "\n",
    "# mturk_raw_data.tail(2)\n",
    "mturk_processed_df = pd.concat(processed_data).sort_values(by = 'unique_id')\n",
    "\n",
    "effectiveness_map = {\n",
    "    'a': 'a',\n",
    "    'b': 'b',\n",
    "    'c': 'c',\n",
    "    'd': 'd',\n",
    "    'e': 'e'\n",
    "}\n",
    "age_map = {\n",
    "    'age_18': 18, \n",
    "    'age_18_24': 24, \n",
    "    'age_25_34': 30, \n",
    "    'age_35_44': 40, \n",
    "    'age_45_54': 50, \n",
    "    'age_55_64': 60, \n",
    "    'age_65': 70, \n",
    "    'unknown': -1, \n",
    "}\n",
    "overall_map = {str(i): i for i in range(1, 6)}\n",
    "\n",
    "def find_multi_choice(s, feature_map, feature):\n",
    "    for e in feature_map:\n",
    "        if s['Answer.{}.{}'.format(feature, e)]:\n",
    "            return feature_map[e]\n",
    "    return ''\n",
    "mturk_processed_df['value_effectiveness'] = mturk_processed_df.apply(lambda x: find_multi_choice(x, effectiveness_map, 'effectiveness'), axis = 1)\n",
    "mturk_processed_df['value_overall'] = mturk_processed_df.apply(lambda x: find_multi_choice(x, overall_map, 'overall'), axis = 1)\n",
    "\n",
    "# 3. demo data\n",
    "col_location = 'Answer.worker_location_live'\n",
    "mturk_processed_df['demo_location'] = mturk_processed_df[col_location]\n",
    "mturk_processed_df['demo_age'] = mturk_processed_df.apply(lambda x: find_multi_choice(x, age_map, 'age'), axis = 1)\n",
    "\n",
    "mturk_processed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>WorkerId</th>\n",
       "      <th>value_overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A1DMXEJGJY02E1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A3RVHUY67SVXQV</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A41APS6V2Z1FJ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A15X8ATAWSRXIF</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A2XZLEY2RCF5VM</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>A5WWHKD82I8UE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>A34YDGVZKRJ0LZ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>A3B7TNVOISSZ2O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>A3PUUVUDORJS8W</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>A3W0SCW5UYEB0F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id        WorkerId  value_overall\n",
       "0          0  A1DMXEJGJY02E1              0\n",
       "1          1  A3RVHUY67SVXQV              0\n",
       "2          2   A41APS6V2Z1FJ              0\n",
       "3          3  A15X8ATAWSRXIF              0\n",
       "4          4  A2XZLEY2RCF5VM              0\n",
       "5          5   A5WWHKD82I8UE              0\n",
       "6          6  A34YDGVZKRJ0LZ              1\n",
       "7          7  A3B7TNVOISSZ2O              0\n",
       "8          8  A3PUUVUDORJS8W              0\n",
       "9          9  A3W0SCW5UYEB0F              0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_overall_data = []\n",
    "mturk_processed_df_overall = mturk_processed_df[['unique_id', 'WorkerId', 'value_overall']]\n",
    "for worker_id in mturk_processed_df_overall.WorkerId.unique():\n",
    "    tmp_df = copy.deepcopy(mturk_processed_df_overall.query('WorkerId == \"{}\"'.format(worker_id)))\n",
    "    tmp_df['value_overall'] = helper_normalize_lst(tmp_df['value_overall'].values, bin = normalize_bin)\n",
    "    all_overall_data.append(tmp_df)\n",
    "all_overall_df = pd.concat(all_overall_data).sort_values(by = 'unique_id')\n",
    "\n",
    "all_overall_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_processed_df['value_overall_norm'] = all_overall_df['value_overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "value_overall_norm\n",
       " 0    1750\n",
       " 1     381\n",
       "-1     369\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mturk_processed_df['value_overall_norm'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 (CAUTIOUS!!) Save to local file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_processed_df.to_csv(data_dir + 'mturk_cleaned_1201/mturk_processed_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Calculate Agreements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mturk_get_kappa_data(mturk_raw_data, column, data_maping = None):\n",
    "    # unique_values = accumulate_data[column + '_agree'].unique()\n",
    "    def count_kappa(data, data_maping):\n",
    "        if data_maping is None:\n",
    "            unique_values = data.unique()\n",
    "        else:\n",
    "            unique_values = list(data_maping.values())\n",
    "        result = {k: 0 for k in unique_values}\n",
    "        for v in data.values:\n",
    "            # v = int(v)\n",
    "            if data_maping is None:\n",
    "                if v in result: result[v] += 1\n",
    "            else:\n",
    "                if data_maping[v] in result: result[data_maping[v]] += 1\n",
    "        return result\n",
    "    kappa_data = mturk_raw_data[[column, 'Input.ads_id']].groupby('Input.ads_id').agg(lambda data: count_kappa(data, data_maping = data_maping))[column].values\n",
    "    kappa_data = pd.DataFrame(list(kappa_data)).fillna(0)\n",
    "    return kappa_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ihome/xli/joh227/.conda/envs/ads_dev/lib/python3.10/site-packages/statsmodels/stats/inter_rater.py:266: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  kappa = (p_mean - p_mean_exp) / (1- p_mean_exp)\n",
      "/ihome/xli/joh227/.conda/envs/ads_dev/lib/python3.10/site-packages/statsmodels/stats/inter_rater.py:266: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  kappa = (p_mean - p_mean_exp) / (1- p_mean_exp)\n",
      "/ihome/xli/joh227/.conda/envs/ads_dev/lib/python3.10/site-packages/statsmodels/stats/inter_rater.py:266: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  kappa = (p_mean - p_mean_exp) / (1- p_mean_exp)\n"
     ]
    }
   ],
   "source": [
    "fleiss_value_lst = []\n",
    "for col in sorted(list(mturk_processed_df.columns)):\n",
    "    if 'acc_' in col:\n",
    "        data_maping = None\n",
    "    elif 'value_' in col:\n",
    "        if 'effectiveness' in col or 'overall' in col:\n",
    "            data_maping = None\n",
    "        else:\n",
    "            # data_maping = {\n",
    "            #     0: 0,\n",
    "            #     -1: 0,\n",
    "            #     1: 1\n",
    "            # }\n",
    "            data_maping = None\n",
    "    else:\n",
    "        continue \n",
    "    tmp_kappa_data = mturk_get_kappa_data(mturk_processed_df, col, data_maping)\n",
    "    # display(tmp_kappa_data)\n",
    "    # fleiss_value = round(statsmodels.stats.inter_rater.fleiss_kappa(tmp_kappa_data, 'randolph'), 4)\n",
    "    fleiss_value = round(statsmodels.stats.inter_rater.fleiss_kappa(tmp_kappa_data), 4)\n",
    "    # print(col, fleiss_value)\n",
    "    fleiss_value_lst.append({\n",
    "        'col': col,\n",
    "        'fleiss': fleiss_value,\n",
    "        'norm': 'norm' in col,\n",
    "        'acc': 'acc_' in col\n",
    "    })\n",
    "fleiss_value_df = pd.DataFrame(fleiss_value_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>fleiss</th>\n",
       "      <th>norm</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acc_norm_raw_artistic</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acc_norm_raw_atypicality</td>\n",
       "      <td>0.2469</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acc_norm_raw_pc</td>\n",
       "      <td>0.2408</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acc_norm_th0_artistic</td>\n",
       "      <td>0.1228</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acc_norm_th0_atypicality</td>\n",
       "      <td>0.0970</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>acc_norm_th0_pc</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>acc_norm_th3_artistic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>acc_norm_th3_atypicality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>acc_norm_th3_pc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>value_overall_norm</td>\n",
       "      <td>0.1053</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         col  fleiss  norm    acc\n",
       "0      acc_norm_raw_artistic  0.1394  True   True\n",
       "1   acc_norm_raw_atypicality  0.2469  True   True\n",
       "2            acc_norm_raw_pc  0.2408  True   True\n",
       "3      acc_norm_th0_artistic  0.1228  True   True\n",
       "4   acc_norm_th0_atypicality  0.0970  True   True\n",
       "5            acc_norm_th0_pc  0.0713  True   True\n",
       "6      acc_norm_th3_artistic     NaN  True   True\n",
       "7   acc_norm_th3_atypicality     NaN  True   True\n",
       "8            acc_norm_th3_pc     NaN  True   True\n",
       "29        value_overall_norm  0.1053  True  False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fleiss_value_df.query('norm == True').sort_values(by = 'col')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>fleiss</th>\n",
       "      <th>norm</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>acc_raw_artistic</td>\n",
       "      <td>0.0639</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>acc_raw_atypicality</td>\n",
       "      <td>0.2113</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>acc_raw_pc</td>\n",
       "      <td>0.1509</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>acc_single_artistic</td>\n",
       "      <td>0.2284</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>acc_single_atypicality</td>\n",
       "      <td>0.3548</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>acc_single_pc</td>\n",
       "      <td>0.3668</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>acc_th0_artistic</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>acc_th0_atypicality</td>\n",
       "      <td>0.1562</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>acc_th0_pc</td>\n",
       "      <td>0.1197</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>acc_th3_artistic</td>\n",
       "      <td>0.1066</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>acc_th3_atypicality</td>\n",
       "      <td>0.0970</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>acc_th3_pc</td>\n",
       "      <td>0.1003</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       col  fleiss   norm   acc\n",
       "9         acc_raw_artistic  0.0639  False  True\n",
       "10     acc_raw_atypicality  0.2113  False  True\n",
       "11              acc_raw_pc  0.1509  False  True\n",
       "12     acc_single_artistic  0.2284  False  True\n",
       "13  acc_single_atypicality  0.3548  False  True\n",
       "14           acc_single_pc  0.3668  False  True\n",
       "15        acc_th0_artistic  0.0859  False  True\n",
       "16     acc_th0_atypicality  0.1562  False  True\n",
       "17              acc_th0_pc  0.1197  False  True\n",
       "18        acc_th3_artistic  0.1066  False  True\n",
       "19     acc_th3_atypicality  0.0970  False  True\n",
       "20              acc_th3_pc  0.1003  False  True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fleiss_value_df.query('(norm == False) & (acc == True)').sort_values(by = 'col')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Intrinsic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 113)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mturk_processed_df = pd.read_csv(data_dir + 'mturk_cleaned_1201/mturk_processed_df.csv')\n",
    "mturk_processed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "instrinsic_task_cols = {\n",
    "    \"value_overall_norm\": \"creativity\",\n",
    "    \"acc_norm_raw_atypicality\": \"atypicality\",\n",
    "    \"acc_norm_raw_pc\": \"originality\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process single task \n",
    "tmp_task_col = 'value_overall_norm' \n",
    "\n",
    "def get_score_distribution(s, offset = 2):\n",
    "    return [i + offset for i in s.values]\n",
    "\n",
    "def get_value_counts(lst):\n",
    "    unique_values, counts = np.unique(lst, return_counts=True)\n",
    "    return dict(zip(unique_values, counts))\n",
    "\n",
    "def get_majority(value_counts):\n",
    "    return sorted(value_counts.items(), key = lambda x: x[1], reverse = True)[0][0] # majority label \n",
    "\n",
    "def get_majority_percentage(value_counts):\n",
    "    majority_count = sorted(value_counts.items(), key = lambda x: x[1], reverse = True)[0][1] \n",
    "    return round(majority_count / sum(value_counts.values()), 2)\n",
    "\n",
    "\n",
    "all_instrinsic_data = None\n",
    "for tmp_task_col in instrinsic_task_cols:\n",
    "    tmp_distribution_data = mturk_processed_df[['Input.ads_id', tmp_task_col]].groupby('Input.ads_id').agg(get_score_distribution)[tmp_task_col]\n",
    "    tmp_value_count_data = tmp_distribution_data.apply(get_value_counts)\n",
    "    tmp_average_data = tmp_distribution_data.apply(lambda x: np.mean(x))\n",
    "    tmp_disagreement_data = tmp_distribution_data.apply(lambda x: np.var(x))\n",
    "    tmp_majority_data = tmp_value_count_data.apply(get_majority)\n",
    "    tmp_majority_percentage_data = tmp_value_count_data.apply(get_majority_percentage)\n",
    "\n",
    "    tmp_instrinsic_data = pd.DataFrame({\n",
    "        'ads_id': tmp_distribution_data.index,\n",
    "        instrinsic_task_cols[tmp_task_col] + '_distribution': tmp_distribution_data.values,\n",
    "        instrinsic_task_cols[tmp_task_col] + '_value_count': tmp_value_count_data.values,\n",
    "        instrinsic_task_cols[tmp_task_col] + '_average': tmp_average_data.values ,\n",
    "        instrinsic_task_cols[tmp_task_col] + '_disagreement': tmp_disagreement_data.values,\n",
    "        instrinsic_task_cols[tmp_task_col] + '_majority': tmp_majority_data.values,\n",
    "        instrinsic_task_cols[tmp_task_col] + '_majority_percentage': tmp_majority_percentage_data.values\n",
    "    })\n",
    "    if all_instrinsic_data is None:\n",
    "        all_instrinsic_data = tmp_instrinsic_data\n",
    "    else:\n",
    "        all_instrinsic_data = all_instrinsic_data.merge(tmp_instrinsic_data, on = 'ads_id')\n",
    "    # all_instrinsic_data.append(tmp_instrinsic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7172000000000002"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_instrinsic_data.creativity_majority_percentage.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6676000000000002"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_instrinsic_data.atypicality_majority_percentage.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6464000000000002"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_instrinsic_data.originality_majority_percentage.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPORTANT: saving data file ####\n",
    "\n",
    "# all_instrinsic_data.to_csv(data_dir + 'mturk_cleaned_1201/modeling_instrinsic_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Pairwise Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creativity_average 938 0.46464646464646464\n",
      "atypicality_average 2631 0.49252525252525253\n",
      "originality_average 2708 0.4862626262626263\n"
     ]
    }
   ],
   "source": [
    "pairwise_task_cols = {\n",
    "    \"creativity_average\": \"creativity\",\n",
    "    \"atypicality_average\": \"atypicality\",\n",
    "    \"originality_average\": \"originality\",\n",
    "}\n",
    "\n",
    "def rebalance_df(df):\n",
    "    df.sample(frac=1).reset_index(drop = True)\n",
    "\n",
    "def arrange_sample(ads_id_1, ads_id_2, diff):\n",
    "    if diff < 0:\n",
    "        ads_id_1, ads_id_2 = ads_id_2, ads_id_1\n",
    "        diff = (-1) * diff \n",
    "    if random.random() > 0.5:\n",
    "        ads_id_1, ads_id_2 = ads_id_2, ads_id_1\n",
    "        diff = (-1) * diff \n",
    "    return ads_id_1, ads_id_2, diff\n",
    "\n",
    "# tmp_task_col = \"creativity_average\"\n",
    "pairwise_threshold = 0.5\n",
    "# all_instrinsic_data[[\"creativity_average\", \"ads_id\"]]\n",
    "all_pairwise_data = []\n",
    "for tmp_task_col in pairwise_task_cols:\n",
    "    tmp_average_data = all_instrinsic_data[tmp_task_col].values \n",
    "    tmp_ads_id = all_instrinsic_data[\"ads_id\"].values \n",
    "\n",
    "    tmp_all_diff = []\n",
    "    counter = 0\n",
    "    for i in range(len(tmp_ads_id)):\n",
    "        for j in range(i + 1, len(tmp_ads_id)):\n",
    "            ads_id_1, ads_id_2 = tmp_ads_id[i], tmp_ads_id[j]\n",
    "            diff = tmp_average_data[i] - tmp_average_data[j]\n",
    "            ads_id_1, ads_id_2, diff = arrange_sample(ads_id_1, ads_id_2, diff)\n",
    "\n",
    "            tmp_all_diff.append({\n",
    "                'ads_pair': ads_id_1 + ', ' + ads_id_2,\n",
    "                tmp_task_col + '_diff': diff\n",
    "            })\n",
    "            if abs(diff) > pairwise_threshold:\n",
    "                counter += 1\n",
    "    tmp_diff_df = pd.DataFrame(tmp_all_diff)\n",
    "    print(tmp_task_col, counter, tmp_diff_df.query('{} > 0'.format(tmp_task_col + '_diff')).shape[0] / tmp_diff_df.shape[0])\n",
    "    \n",
    "\n",
    "    #### IMPORTANT: saving data file ####\n",
    "    # tmp_diff_df.to_csv(data_dir + 'mturk_cleaned_1201/modeling_{}_diff.csv'.format(tmp_task_col), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ads_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
