{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7baf77f-384a-48e0-8bb8-9cda6b975422",
   "metadata": {},
   "source": [
    "# 1 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae09f6cd-96d9-4aae-afbe-75a979124dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77d750d6-c057-4b33-88b1-a06f6f21efe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_data_dir = '../data/mturk_data/'\n",
    "output_dir = '../data/outputs/'\n",
    "original_data_dir = '../data/original_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46fc20fb-2b92-49d9-8010-3563d378a431",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_list = [\n",
    "    \"atypicality\", \n",
    "    \"creativity\", \n",
    "    \"originality\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b835bbe-430f-4c68-8b4b-33b3abb8102f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d24060c4-43ae-4b7a-9c23-d115a04b7253",
   "metadata": {},
   "source": [
    "# 2 Intrinsic Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d2eb4ad-89bb-4ae8-a027-27198ab404b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_intrinsic(intrinsic_pred_task):\n",
    "    # single_label \n",
    "    true_labels = [pred['true_average'] for pred in intrinsic_pred_task]\n",
    "    pred_labels = [pred['labels'][0] for pred in intrinsic_pred_task]\n",
    "    # if self.debug:\n",
    "    #     print('true_labels[:3]:', true_labels[:3])\n",
    "    #     print('pred_labels[:3]:', pred_labels[:3])\n",
    "    # res = stats.pearsonr(true_labels, pred_labels)\n",
    "    single_label_corr = stats.spearmanr(true_labels, pred_labels) # get pearson r\n",
    "    \n",
    "    # distribution\n",
    "    distribution_diff = None\n",
    "    pred_distributions = [[p[0] for p in pred['label_distribution']] for pred in intrinsic_pred_task]\n",
    "    true_distributions = [pred['true_distribution'] for pred in intrinsic_pred_task]\n",
    "    if len(true_distributions) > 0 and len(true_distributions[0]) > 0:\n",
    "        # max_len = max([len(pred_distributions), len(true_distributions)])\n",
    "        # print(\"pred_distributions[:max_len]:\", pred_distributions[:max_len])\n",
    "        # print(\"true_distributions[:max_len]:\", true_distributions[:max_len])\n",
    "        distribution_diff = []\n",
    "        for i in range(len(pred_distributions)):\n",
    "            # max_len = max([len(pred_distributions), len(true_distributions)])\n",
    "            distribution_diff.append(stats.kstest(\n",
    "                pred_distributions[i], true_distributions[i]\n",
    "            ))\n",
    "        # distribution_diff = stats.kstest(pred_distributions[:max_len], true_distributions[:max_len])\n",
    "        # distribution_diff = stats.kstest(pred_distributions, true_distributions)\n",
    "    \n",
    "    # disagreement\n",
    "    pred_disagreements = [pred['disagreements'][0] for pred in intrinsic_pred_task]\n",
    "    true_disagreements = [pred['true_disagreement'] for pred in intrinsic_pred_task]\n",
    "    # print(\"pred_disagreements:\", pred_disagreements)\n",
    "    # print(\"true_disagreements:\", true_disagreements)\n",
    "    disagreement_corr = stats.spearmanr(pred_disagreements, true_disagreements) #.statistic # get pearson r\n",
    "\n",
    "    return {\n",
    "        \"single_label_corr\": round(single_label_corr.statistic, 4),\n",
    "        \"single_label_corr_p\": round(single_label_corr.pvalue, 4),\n",
    "        \"distribution_ks\": np.mean([round(d.statistic, 4) for d in distribution_diff]) if distribution_diff is not None else None,\n",
    "        \"distribution_p\": np.mean([round(d.pvalue, 4) for d in distribution_diff]) if distribution_diff is not None else None,\n",
    "        \"disagreement_corr\": round(disagreement_corr.statistic, 4),\n",
    "        \"disagreement_corr_p\": round(disagreement_corr.pvalue, 4),\n",
    "    }\n",
    "        \n",
    "def eval_batch_intrinsic(batch_pred):\n",
    "    intrinsic_pred = batch_pred['intrinsic']\n",
    "    # pairwise_pred = batch_pred['pairwise']\n",
    "    eval_results = []\n",
    "    for task in task_list:\n",
    "        tmp_result = eval_intrinsic(intrinsic_pred[task])\n",
    "        tmp_result['task'] = task\n",
    "        # tmp_result['intrinsic_single_label'] = intrinsic_results['single_label_corr']\n",
    "        # tmp_result['intrinsic_distribution'] = intrinsic_results['distribution_p']\n",
    "        # tmp_result['intrinsic_disagreement'] = intrinsic_results['disagreement_corr']\n",
    "        # tmp_result['pairwise'] = eval_pairwise(pairwise_pred[task])\n",
    "        eval_results.append(tmp_result)\n",
    "    eval_result_df = pd.DataFrame(eval_results)\n",
    "    # display(eval_result_df)\n",
    "    return eval_result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97ac971c-fe1b-4749-886f-96b7c9b62e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>single_label_corr</th>\n",
       "      <th>single_label_corr_p</th>\n",
       "      <th>distribution_ks</th>\n",
       "      <th>distribution_p</th>\n",
       "      <th>disagreement_corr</th>\n",
       "      <th>disagreement_corr_p</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7408</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0983</td>\n",
       "      <td>0.6802</td>\n",
       "      <td>atypicality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1371</td>\n",
       "      <td>0.5643</td>\n",
       "      <td>creativity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7643</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.6595</td>\n",
       "      <td>originality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   single_label_corr  single_label_corr_p distribution_ks distribution_p  \\\n",
       "0             0.7408               0.0002            None           None   \n",
       "1             0.7845               0.0000            None           None   \n",
       "2             0.7643               0.0001            None           None   \n",
       "\n",
       "   disagreement_corr  disagreement_corr_p         task  \n",
       "0             0.0983               0.6802  atypicality  \n",
       "1             0.1371               0.5643   creativity  \n",
       "2             0.1050               0.6595  originality  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_pred_gpt4 = pickle.load(open(output_dir + 'pickles/batch_pred_gpt4.pkl', 'rb'))\n",
    "eval_batch_intrinsic(batch_pred_gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f2b84f4-207e-4033-ada4-9c4608d4921e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>single_label_corr</th>\n",
       "      <th>single_label_corr_p</th>\n",
       "      <th>distribution_ks</th>\n",
       "      <th>distribution_p</th>\n",
       "      <th>disagreement_corr</th>\n",
       "      <th>disagreement_corr_p</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.406005</td>\n",
       "      <td>0.155170</td>\n",
       "      <td>0.1289</td>\n",
       "      <td>0.5881</td>\n",
       "      <td>atypicality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1549</td>\n",
       "      <td>0.5144</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.3104</td>\n",
       "      <td>0.1829</td>\n",
       "      <td>creativity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2312</td>\n",
       "      <td>0.3267</td>\n",
       "      <td>0.333340</td>\n",
       "      <td>0.424415</td>\n",
       "      <td>0.2385</td>\n",
       "      <td>0.3113</td>\n",
       "      <td>originality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   single_label_corr  single_label_corr_p  distribution_ks  distribution_p  \\\n",
       "0             0.0300               0.9000         0.406005        0.155170   \n",
       "1             0.1549               0.5144         0.512000        0.148515   \n",
       "2             0.2312               0.3267         0.333340        0.424415   \n",
       "\n",
       "   disagreement_corr  disagreement_corr_p         task  \n",
       "0             0.1289               0.5881  atypicality  \n",
       "1             0.3104               0.1829   creativity  \n",
       "2             0.2385               0.3113  originality  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_pred_llava_7b = pickle.load(open(output_dir + 'pickles/batch_pred_llava-hf-llava-v1.6-mistral-7b-hf.pkl', 'rb'))\n",
    "eval_batch_intrinsic(batch_pred_llava_7b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed634374-ab63-49d9-820f-0496ef1d8a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/slurm-919087/ipykernel_2905/341864058.py:33: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  disagreement_corr = stats.spearmanr(pred_disagreements, true_disagreements) #.statistic # get pearson r\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>single_label_corr</th>\n",
       "      <th>single_label_corr_p</th>\n",
       "      <th>distribution_ks</th>\n",
       "      <th>distribution_p</th>\n",
       "      <th>disagreement_corr</th>\n",
       "      <th>disagreement_corr_p</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3124</td>\n",
       "      <td>0.1799</td>\n",
       "      <td>0.485330</td>\n",
       "      <td>0.120605</td>\n",
       "      <td>0.1458</td>\n",
       "      <td>0.5398</td>\n",
       "      <td>atypicality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.1277</td>\n",
       "      <td>0.5915</td>\n",
       "      <td>0.638670</td>\n",
       "      <td>0.013125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>creativity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5264</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.472665</td>\n",
       "      <td>0.200510</td>\n",
       "      <td>-0.4729</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>originality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   single_label_corr  single_label_corr_p  distribution_ks  distribution_p  \\\n",
       "0             0.3124               0.1799         0.485330        0.120605   \n",
       "1            -0.1277               0.5915         0.638670        0.013125   \n",
       "2             0.5264               0.0171         0.472665        0.200510   \n",
       "\n",
       "   disagreement_corr  disagreement_corr_p         task  \n",
       "0             0.1458               0.5398  atypicality  \n",
       "1                NaN                  NaN   creativity  \n",
       "2            -0.4729               0.0352  originality  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_pred_llava_7b = pickle.load(open(output_dir + 'pickles/batch_pred_llava-hf-llava-v1.6-vicuna-13b-hf.pkl', 'rb'))\n",
    "eval_batch_intrinsic(batch_pred_llava_7b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0247a8b8-d11c-4348-b008-5bbf19c2ca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_pred_gpt4_pairwise = batch_pred_gpt4['pairwise']\n",
    "# batch_pred_gpt4_pairwise['atypicality'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad2008a4-049f-48d1-92b5-f77cc52941d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_pred_llava_7b_pairwise = batch_pred_llava_7b['pairwise']\n",
    "# batch_pred_llava_7b_pairwise['atypicality'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7413daf5-b5a4-488d-a900-c6ae7c1d60d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046a6af7-9461-4177-963d-56a7c6342bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da90253-2c77-4a17-96c4-d22ae55b0d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3605340-1d5f-4cb0-ae5c-01beb9516e0c",
   "metadata": {},
   "source": [
    "# 3 Pairwise Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21d44ecd-a416-49c2-903a-1a207442a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "192bc48a-15bf-4be4-bb1a-d97d749cbcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pairwise_single(pairwise_pred_task):\n",
    "    correct = 0\n",
    "    all_target = []\n",
    "    all_pred = [pred['labels'][0] for pred in pairwise_pred_task]\n",
    "    for pred in pairwise_pred_task:\n",
    "        if pred['true'] > 0:\n",
    "            all_target.append(1)\n",
    "        else:\n",
    "            all_target.append(2)\n",
    "\n",
    "    # filter out str predictions \n",
    "    all_pred_cleaned = []\n",
    "    all_target_cleaned = []\n",
    "    num_dropped = 0\n",
    "    for i in range(len(all_pred)):\n",
    "        if isinstance(all_pred[i], str): \n",
    "            num_dropped += 1\n",
    "            continue \n",
    "        all_pred_cleaned.append(all_pred[i])\n",
    "        all_target_cleaned.append(all_target[i])\n",
    "    # print('# of dp dropped:', num_dropped)\n",
    "        \n",
    "    all_pred = all_pred_cleaned\n",
    "    all_target = all_target_cleaned\n",
    "    \n",
    "    # for pred in pairwise_pred_task:\n",
    "    #     if pred['true'] > 0 and pred['labels'][0] == 1:\n",
    "    #         correct += 1\n",
    "    #     elif pred['true'] < 0 and pred['labels'][0] == 2: ## TODO Check correctness\n",
    "    #         correct += 1\n",
    "    # print(correct)\n",
    "    if len(pairwise_pred_task) == 0: return 0, 0, 0\n",
    "    # return round(correct / len(pairwise_pred_task), 4)\n",
    "\n",
    "    \n",
    "    acc = round(accuracy_score(all_target, all_pred), 4)\n",
    "    f1 = round(f1_score(all_target, all_pred), 4)\n",
    "    return acc, f1, num_dropped\n",
    "\n",
    "def eval_batch_pairwise(batch_pred):\n",
    "    # intrinsic_pred = batch_pred['intrinsic']\n",
    "    pairwise_pred = batch_pred['pairwise']\n",
    "    eval_results = []\n",
    "    for task in task_list:\n",
    "        # tmp_result = eval_intrinsic(intrinsic_pred[task])\n",
    "        tmp_result = {'task': task}\n",
    "        # tmp_result['intrinsic_single_label'] = intrinsic_results['single_label_corr']\n",
    "        # tmp_result['intrinsic_distribution'] = intrinsic_results['distribution_p']\n",
    "        # tmp_result['intrinsic_disagreement'] = intrinsic_results['disagreement_corr']\n",
    "        acc, f1, num_dropped = eval_pairwise_single(pairwise_pred[task])\n",
    "        print('task:', task, '# of dp dropped:', num_dropped)\n",
    "        tmp_result['pairwise_accuracy'] = acc\n",
    "        tmp_result['pairwise_f1'] = f1\n",
    "        tmp_result['pred_1'] = sum([pred['labels'][0] == 1 for pred in batch_pred['pairwise'][task]]) / len(batch_pred['pairwise'][task])\n",
    "        tmp_result['pos_labels'] = sum([pred['true'] > 0 for pred in batch_pred['pairwise'][task]]) / len(batch_pred['pairwise'][task])\n",
    "        tmp_result['dp_count'] = len(batch_pred['pairwise'][task])\n",
    "        eval_results.append(tmp_result)\n",
    "    eval_result_df = pd.DataFrame(eval_results)\n",
    "    # display(eval_result_df)\n",
    "    return eval_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d11e882f-8927-46df-95c9-5bf373d14ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: atypicality # of dp dropped: 0\n",
      "task: creativity # of dp dropped: 0\n",
      "task: originality # of dp dropped: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>pairwise_accuracy</th>\n",
       "      <th>pairwise_f1</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pos_labels</th>\n",
       "      <th>dp_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atypicality</td>\n",
       "      <td>0.5189</td>\n",
       "      <td>0.6277</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>creativity</td>\n",
       "      <td>0.6721</td>\n",
       "      <td>0.7872</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>originality</td>\n",
       "      <td>0.7755</td>\n",
       "      <td>0.8736</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          task  pairwise_accuracy  pairwise_f1    pred_1  pos_labels  dp_count\n",
       "0  atypicality             0.5189       0.6277  0.500000    0.792453       106\n",
       "1   creativity             0.6721       0.7872  0.672131    0.868852        61\n",
       "2  originality             0.7755       0.8736  0.959184    0.816327        98"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_pred_llava_7b_pairwise = pickle.load(open('../data/outputs/pickles/batch_pred_llava-hf-llava-v1.6-mistral-7b-hf_0611_175821.pkl', 'rb'))\n",
    "eval_batch_pairwise(batch_pred_llava_7b_pairwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c23daee-921f-481b-b0e0-739276ad037d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: atypicality # of dp dropped: 0\n",
      "task: creativity # of dp dropped: 0\n",
      "task: originality # of dp dropped: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>pairwise_accuracy</th>\n",
       "      <th>pairwise_f1</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pos_labels</th>\n",
       "      <th>dp_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atypicality</td>\n",
       "      <td>0.7264</td>\n",
       "      <td>0.8221</td>\n",
       "      <td>0.745283</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>creativity</td>\n",
       "      <td>0.7049</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.704918</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>originality</td>\n",
       "      <td>0.8673</td>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.887755</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          task  pairwise_accuracy  pairwise_f1    pred_1  pos_labels  dp_count\n",
       "0  atypicality             0.7264       0.8221  0.745283    0.792453       106\n",
       "1   creativity             0.7049       0.8125  0.704918    0.868852        61\n",
       "2  originality             0.8673       0.9222  0.887755    0.816327        98"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_pred_llava_13b_pairwise = pickle.load(open('../data/outputs/pickles/batch_pred_llava-hf-llava-v1.6-vicuna-13b-hf_0611_224428.pkl', 'rb'))\n",
    "eval_batch_pairwise(batch_pred_llava_13b_pairwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "321103ad-7d4e-4ed6-bf7b-0ebff19eee0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: atypicality # of dp dropped: 0\n",
      "task: creativity # of dp dropped: 0\n",
      "task: originality # of dp dropped: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>pairwise_accuracy</th>\n",
       "      <th>pairwise_f1</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pos_labels</th>\n",
       "      <th>dp_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atypicality</td>\n",
       "      <td>0.7647</td>\n",
       "      <td>0.7846</td>\n",
       "      <td>0.554622</td>\n",
       "      <td>0.537815</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>creativity</td>\n",
       "      <td>0.8966</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>originality</td>\n",
       "      <td>0.9245</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          task  pairwise_accuracy  pairwise_f1    pred_1  pos_labels  dp_count\n",
       "0  atypicality             0.7647       0.7846  0.554622    0.537815       119\n",
       "1   creativity             0.8966       0.8800  0.379310    0.482759        58\n",
       "2  originality             0.9245       0.9200  0.471698    0.471698       106"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_pred_gpt4_pairwise = pickle.load(open('../data/outputs/pickles/batch_pred_gpt4_0612_205705.pkl', 'rb'))\n",
    "eval_batch_pairwise(batch_pred_gpt4_pairwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2769dc24-a06a-4c0c-a63a-052fab2b7ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6982c64c-f8f9-4bd1-9ecb-c1026cb986b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fe3c27-e9cc-485b-bde9-6267090ea584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a1d27d-987d-467c-a2c4-cb2f32517b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1fc637-c9c2-4ae0-880f-f76a3b3956d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2c1ab00-7c32-4cc5-8247-6acf28d51afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(mturk_data_dir + \"subset_0.5/modeling_atypicality_average_diff.csv\").atypicality_average_diff.apply(lambda x: abs(x) > 0.5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eac3271b-b54a-47e8-9b2d-8409f50c7407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(mturk_data_dir + \"subset_0.5/modeling_creativity_average_diff.csv\").creativity_average_diff.apply(lambda x: abs(x) > 0.5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abceebac-c7d7-4acf-9537-ff35a20ad42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(mturk_data_dir + \"subset_0.5/modeling_originality_average_diff.csv\").originality_average_diff.apply(lambda x: abs(x) > 0.5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4071ff5b-e392-4e36-8777-9fa2aa218dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
